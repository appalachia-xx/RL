{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys,os\n",
    "curr_path = os.path.abspath('')\n",
    "parent_path = os.path.dirname(curr_path)\n",
    "sys.path.append(parent_path)\n",
    "from SimpleGrid import DrunkenWalkEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_seed(env,seed = 1):\n",
    "    ## fixed random seed\n",
    "    import numpy as np\n",
    "    import random\n",
    "    import os\n",
    "    env.seed(seed) \n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jingyul/anaconda3/lib/python3.11/site-packages/gym/utils/seeding.py:41: DeprecationWarning: \u001b[33mWARN: Function `rng.rand(*size)` is marked as deprecated and will be removed in the future. Please use `Generator.random(size)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = DrunkenWalkEnv(map_name = \"walkInThePark\")\n",
    "all_seed(env, seed = 1) # random seed = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def value_iteration(env, theta=0.005, discount_factor=0.9):\n",
    "    Q = np.zeros((env.nS, env.nA)) # initilize Q table\n",
    "    count = 0\n",
    "    while True:\n",
    "        delta = 0.0\n",
    "        Q_tmp = np.zeros((env.nS, env.nA))\n",
    "        for state in range(env.nS):\n",
    "            for a in range(env.nA):\n",
    "                accum = 0.0\n",
    "                reward_total = 0.0\n",
    "                for prob, next_state, reward, done in env.P[state][a]:\n",
    "                    accum += prob* np.max(Q[next_state, :])\n",
    "                    reward_total += prob * reward\n",
    "                Q_tmp[state, a] = reward_total + discount_factor * accum\n",
    "                delta = max(delta, abs(Q_tmp[state, a] - Q[state, a]))\n",
    "        Q = Q_tmp\n",
    "        \n",
    "        count += 1\n",
    "        # Even if the algorithm does not converge, it exits the loop after 100 iterations\n",
    "        if delta < theta or count > 100: \n",
    "            break \n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.23719387e+20 1.82636701e+20 1.23719387e+20 1.93254119e+20]\n",
      " [2.61716488e+20 3.67074008e+20 1.70773081e+20 4.07982220e+20]\n",
      " [5.72302298e+20 8.18297648e+20 3.68942124e+20 8.88139558e+20]\n",
      " [1.25285719e+21 1.83061666e+21 8.09487798e+20 1.93498694e+21]\n",
      " [2.74346159e+21 4.09889186e+21 1.77745541e+21 4.21584138e+21]\n",
      " [5.97711269e+21 9.18524478e+21 3.87243020e+21 8.92890949e+21]\n",
      " [1.26283608e+22 1.94070718e+22 8.29912881e+21 1.88916901e+22]\n",
      " [2.42792050e+22 4.10314670e+22 1.51206638e+22 2.05776617e+22]\n",
      " [1.67805357e+20 3.82913244e+20 2.48131345e+20 3.65746831e+20]\n",
      " [3.54587441e+20 7.46554902e+20 3.43970023e+20 7.91550449e+20]\n",
      " [7.83532505e+20 1.66680989e+21 7.42624293e+20 1.77008196e+21]\n",
      " [1.73415136e+21 3.73992802e+21 1.66430945e+21 3.96941085e+21]\n",
      " [3.83998702e+21 8.39323247e+21 3.73561674e+21 8.90911318e+21]\n",
      " [6.00915460e+21 1.99985690e+22 5.89220509e+21 2.00123096e+22]\n",
      " [1.79685960e+22 4.22483439e+22 1.82249313e+22 3.99186912e+22]\n",
      " [3.27215062e+22 8.93253115e+22 3.32368879e+22 4.22407073e+22]\n",
      " [3.46229977e+20 8.32082374e+20 5.36465771e+20 7.69007199e+20]\n",
      " [7.29366929e+20 1.66105532e+21 7.46533342e+20 1.66384217e+21]\n",
      " [1.63358105e+21 3.70922895e+21 1.58858550e+21 3.72557334e+21]\n",
      " [3.66796495e+21 8.34194353e+21 3.56469288e+21 8.36727717e+21]\n",
      " [8.23946376e+21 1.87646297e+22 8.00998093e+21 1.87942544e+22]\n",
      " [1.85158509e+22 4.22136049e+22 1.79999702e+22 4.22159008e+22]\n",
      " [3.98021984e+22 9.48258961e+22 3.97884578e+22 8.93880167e+22]\n",
      " [7.22898950e+22 2.00497611e+23 7.46195477e+22 9.46655467e+22]\n",
      " [7.58391281e+20 1.81277009e+21 1.17374019e+21 1.71511973e+21]\n",
      " [1.58748050e+21 3.71899325e+21 1.65055568e+21 3.71148891e+21]\n",
      " [3.56148410e+21 8.32834957e+21 3.55869725e+21 8.32868616e+21]\n",
      " [8.00634501e+21 1.87344387e+22 7.99000063e+21 1.87339012e+22]\n",
      " [1.77116638e+22 3.98417974e+22 1.76863301e+22 4.21459531e+22]\n",
      " [3.97885993e+22 8.93837281e+22 3.97589745e+22 9.48204755e+22]\n",
      " [6.27500096e+22 2.13337085e+23 6.27477138e+22 2.13337025e+23]\n",
      " [1.62318794e+23 4.50379586e+23 1.67756674e+23 2.12657290e+23]\n",
      " [1.66518821e+21 3.94955725e+21 2.57017783e+21 3.84000135e+21]\n",
      " [3.55942984e+21 8.34640480e+21 3.65708020e+21 8.34020751e+21]\n",
      " [7.99010659e+21 1.87336440e+22 7.99761094e+21 1.87333337e+22]\n",
      " [1.76868898e+22 4.21472222e+22 1.76865532e+22 3.98385886e+22]\n",
      " [3.90634582e+22 8.92527093e+22 3.90639957e+22 8.93800922e+22]\n",
      " [8.78086092e+22 2.00198958e+23 8.55044534e+22 2.00500284e+23]\n",
      " [1.97469967e+23 4.50363778e+23 1.92033220e+23 4.50379728e+23]\n",
      " [3.64805154e+23 1.01166994e+24 3.64805214e+23 4.76157875e+23]\n",
      " [3.12086359e+21 4.30914906e+21 5.09260844e+21 8.60507920e+21]\n",
      " [6.75884676e+21 8.83785282e+21 6.86840266e+21 1.87482765e+22]\n",
      " [1.51860355e+22 1.98351789e+22 1.51922327e+22 4.21479547e+22]\n",
      " [2.78914431e+22 5.02045293e+22 2.78917534e+22 9.48310480e+22]\n",
      " [7.22596566e+22 9.45424689e+22 7.45682901e+22 2.00199518e+23]\n",
      " [1.62280274e+23 2.11660650e+23 1.62152892e+23 4.49668262e+23]\n",
      " [3.64803220e+23 4.76104267e+23 3.64501894e+23 1.01163228e+24]\n",
      " [1.87444498e+24 2.27607704e+24 1.87442903e+24 2.27607704e+24]]\n"
     ]
    }
   ],
   "source": [
    "Q = value_iteration(env)\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 1, 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 1]\n"
     ]
    }
   ],
   "source": [
    "policy = np.zeros([env.nS, env.nA]) # initialize a policy table\n",
    "for state in range(env.nS):\n",
    "    best_action = np.argmax(Q[state, :]) # select policy according Q table given by value iternation\n",
    "    policy[state, best_action] = 1\n",
    "\n",
    "policy = [int(np.argwhere(policy[i]==1)) for i in range(env.nS) ]\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episode = 1000 # test 1000 times\n",
    "def test(env,policy):\n",
    "    \n",
    "    rewards = []  # rewards for all rounds\n",
    "    success = []  # whether the round is successful to the end\n",
    "    for i_ep in range(num_episode):\n",
    "        ep_reward = 0  # the reward for each episode\n",
    "        state = env.reset()  # reset environment -> restart a new episode, state=0\n",
    "        while True:\n",
    "            action = policy[state]  # choose an action\n",
    "            next_state, reward, done, _ = env.step(action)  # interact with the environment\n",
    "            state = next_state  # update state\n",
    "            ep_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        if state==47: # reach the end\n",
    "            success.append(1)\n",
    "        else:\n",
    "            success.append(0)\n",
    "        rewards.append(ep_reward)\n",
    "    acc_suc = np.array(success).sum()/num_episode\n",
    "    print(\"The successful rate of the test：\", acc_suc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The successful rate of the test： 0.603\n"
     ]
    }
   ],
   "source": [
    "test(env,policy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
